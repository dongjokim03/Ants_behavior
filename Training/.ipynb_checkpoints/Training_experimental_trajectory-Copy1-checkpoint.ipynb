{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c1ee2b0",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cbf2477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib as mpl\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device name:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cef15df",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24415a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         AntID     xcor_mm     ycor_mm  Time_frame  Colony SizeClass\n",
      "40706715   V12 -266.888916   41.477314      106082     704         S\n",
      "40706716   V13 -204.648226  147.555599      106082     704         S\n",
      "40706717   V14 -143.306903 -195.905235      106082     704         S\n",
      "40706718   V15 -260.857649  -76.024630      106082     704         S\n",
      "40706719   V16  -14.788834 -215.886498      106082     704         S\n"
     ]
    }
   ],
   "source": [
    "# Define default data type for tensors\n",
    "dtype = torch.float32  # Change to torch.double if float64 precision is preferred\n",
    "\n",
    "# Load experimental data from a CSV file\n",
    "# Specify the full file path where 'All_Data_frames.csv' is located\n",
    "data = pd.read_csv('../All_Data_frames.csv')\n",
    "print(data.tail())  # Display the last few rows of the dataset\n",
    "\n",
    "\n",
    "##### Filter data for a specific colony and ant size ####\n",
    "num_colony = 620  # Colony ID\n",
    "size_ant = 'L'  # Ant size category\n",
    "temp = data.loc[(data.Colony == num_colony) & (data.SizeClass == size_ant)][['xcor_mm', 'ycor_mm']]\n",
    "\n",
    "\n",
    "# Define time step and subsampling factor\n",
    "num_mul = 30  # Time sampling factor\n",
    "dt = 1 / 29.97 * num_mul  # Time step (seconds)\n",
    "\n",
    "# Convert position data to tensor format (meters) and downsample\n",
    "data_x = torch.tensor(temp.to_numpy()[:, 0] / 1000, dtype=dtype).reshape(-1, 16)  # X-coordinates (m)\n",
    "data_x = data_x[::num_mul, :]  # Apply sampling\n",
    "data_y = torch.tensor(temp.to_numpy()[:, 1] / 1000, dtype=dtype).reshape(-1, 16)  # Y-coordinates (m)\n",
    "data_y = data_y[::num_mul, :]  # Apply sampling\n",
    "\n",
    "# Generate time sequence tensor\n",
    "data_t = torch.linspace(0, dt * (data_x.shape[0] - 1), data_x.shape[0], dtype=dtype)\n",
    "\n",
    "# Delete original data to free memory\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415294dd",
   "metadata": {},
   "source": [
    "# Define the CustomDataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de8a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class for handling time-sequenced position data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_x, data_y, data_t):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with time (data_t), x-coordinates (data_x), and y-coordinates (data_y).\n",
    "\n",
    "        Args:\n",
    "            data_x (Tensor): X-coordinates of the ant positions.\n",
    "            data_y (Tensor): Y-coordinates of the ant positions.\n",
    "            data_t (Tensor): Time steps corresponding to position data.\n",
    "        \"\"\"\n",
    "        self.data_t = data_t\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of data points in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data_t)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a single data interval (time, x-position, y-position).\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the data point.\n",
    "\n",
    "        Returns:\n",
    "            t_train, x_train, y_train corresponding to time, x-coordinate, and y-coordinate.\n",
    "        \"\"\"\n",
    "        t_train = self.data_t[idx]\n",
    "        x_train = self.data_x[idx]\n",
    "        y_train = self.data_y[idx]\n",
    "        \n",
    "        return t_train, x_train, y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1807a2",
   "metadata": {},
   "source": [
    "# Trajectory networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78752fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trajectory networks\n",
    "\"\"\"\n",
    "\n",
    "# Define a small positive constant to prevent division by zero\n",
    "# Change to a different value if needed for numerical stability\n",
    "eps = 1e-9  \n",
    "\n",
    "class PINN_ODE(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network for training Ordinary Differential Equations (ODEs).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_num, output_num, bias=True):\n",
    "        \"\"\"\n",
    "        Initializes the neural network model.\n",
    "\n",
    "        Args:\n",
    "            input_num (int): Number of input features.\n",
    "            output_num (int): Number of output features (2 * number of ants).\n",
    "            bias (bool): Whether to use bias in linear layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_ants = output_num // 2  # Number of ants (each ant has x and y coordinates)\n",
    "        self.bias = bias\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(input_num, 32, bias=bias)\n",
    "        self.fc2 = nn.Linear(32, 32, bias=bias)\n",
    "        self.fc3 = nn.Linear(32, 32, bias=bias)\n",
    "        self.fc4 = nn.Linear(32, output_num, bias=bias)\n",
    "\n",
    "        self.reset_parameters()  # Initialize weights and biases\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Predicted output.\n",
    "        \"\"\"\n",
    "        self.input = x  # Store input values\n",
    "\n",
    "        # Normalize input data (-1 to 1)\n",
    "        x = (x - 50) / 50\n",
    "\n",
    "        # Pass through fully connected layers with activation functions\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        x = self.fc4(x) * (1e-1)  # Scale output\n",
    "\n",
    "        return x\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes network parameters using Xavier uniform initialization.\n",
    "        \"\"\"\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc2.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc3.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc4.weight, gain=1)\n",
    "\n",
    "        if self.bias:\n",
    "            nn.init.constant_(self.fc1.bias, 0.0)\n",
    "            nn.init.constant_(self.fc2.bias, 0.0)\n",
    "            nn.init.constant_(self.fc3.bias, 0.0)\n",
    "            nn.init.constant_(self.fc4.bias, 0.0)\n",
    "\n",
    "    def loss(self, x_ode, data_exp):\n",
    "        \"\"\"\n",
    "        Computes the loss function.\n",
    "\n",
    "        Args:\n",
    "            x_ode (Tensor): Input tensor representing time.\n",
    "            data_exp (Tensor): Experimental data for comparison.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Computed loss value.\n",
    "        \"\"\"\n",
    "        pred1 = self.forward(x_ode)  # Model predictions\n",
    "        num_ant = pred1.shape[1] // 2  # Number of ants\n",
    "\n",
    "        loss_func = nn.MSELoss().to(device)  # Mean Squared Error loss function\n",
    "\n",
    "        # Extract x and y positions from predicted output\n",
    "        pos_x = pred1[:, 0:num_ant]\n",
    "        pos_y = pred1[:, num_ant:]\n",
    "\n",
    "        # Compute the magnitude of position vectors\n",
    "        self.r_mag = torch.sqrt(torch.square(pos_x) + torch.square(pos_y))\n",
    "\n",
    "        ####### Compute velocity of ants #########\n",
    "        for i in range(pred1.size(1)):\n",
    "            temp = torch.zeros_like(pred1)\n",
    "            temp[:, i] = 1\n",
    "            grads, = autograd.grad(pred1, self.input, grad_outputs=temp, create_graph=True)\n",
    "            if i == 0:\n",
    "                self.u = grads  # Initialize velocity tensor\n",
    "            else:\n",
    "                self.u = torch.hstack((self.u, grads))  # Stack velocity components\n",
    "\n",
    "        # Extract velocity components\n",
    "        self.vel_x = self.u[:, 0:num_ant]\n",
    "        self.vel_y = self.u[:, num_ant:]\n",
    "\n",
    "        # Compute velocity magnitude\n",
    "        self.u_mag = torch.sqrt(torch.square(self.vel_x) + torch.square(self.vel_y))\n",
    "\n",
    "        # Normalize velocity components to obtain unit vectors\n",
    "        self.vel_x_unit = self.vel_x / self.u_mag\n",
    "        self.vel_y_unit = self.vel_y / self.u_mag\n",
    "\n",
    "        ####### Compute acceleration of ants #########\n",
    "        for i in range(pred1.size(1)):\n",
    "            temp = torch.zeros_like(pred1)\n",
    "            temp[:, i] = 1\n",
    "            grads, = autograd.grad(self.u, self.input, grad_outputs=temp, create_graph=True)\n",
    "            if i == 0:\n",
    "                self.accel = grads  # Initialize acceleration tensor\n",
    "            else:\n",
    "                self.accel = torch.hstack((self.accel, grads))  # Stack acceleration components\n",
    "\n",
    "        # Compute loss between predictions and experimental data\n",
    "        self.loss_data = loss_func(pred1, data_exp)\n",
    "\n",
    "        # Total loss (currently only data loss is considered)\n",
    "        loss_ode = self.loss_data\n",
    "\n",
    "        return loss_ode\n",
    "\n",
    "\n",
    "def closure_ode():\n",
    "    \"\"\"\n",
    "    Closure function for the L-BFGS optimizer.\n",
    "\n",
    "    This function evaluates the loss function and performs backpropagation\n",
    "    for updating the neural network parameters.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Computed loss value.\n",
    "    \"\"\"\n",
    "    global loss_value_ode_LBFGS, iter_num\n",
    "\n",
    "    model_ode.train()\n",
    "    optimizer_LBFGS.zero_grad()\n",
    "\n",
    "    # Compute ODE loss\n",
    "    loss_ode = model_ode.loss(input_ode, XY_test.to(device))\n",
    "\n",
    "    # Perform backpropagation only if loss is finite\n",
    "    if torch.isfinite(loss_ode).item():\n",
    "        loss_ode.backward() \n",
    "\n",
    "    return loss_ode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18da297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define time (T), x-coordinates (X), and y-coordinates (Y) ###\n",
    "\n",
    "num_t = 100  # Number of time steps\n",
    "\n",
    "# Create dataset and data loader for training\n",
    "dataset = CustomDataset(data_x, data_y, data_t)\n",
    "train_loader = DataLoader(dataset, batch_size=num_t, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbc912c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-12 16:18:33.032303\n",
      "2.8158920031273738e-05\n",
      "0 saved\n"
     ]
    }
   ],
   "source": [
    "# Record start time\n",
    "tik = time.time()\n",
    "\n",
    "# Print current date and time\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "\n",
    "# Define training parameters\n",
    "num_ants = 16  # Number of ants in the system\n",
    "epoch_adam = 100  # Number of epochs for Adam optimizer\n",
    "epoch_LBFGS = 3000  # Number of epochs for L-BFGS optimizer\n",
    "patience = -51  # Early stopping patience (negative value indicates backward indexing)\n",
    "tolerance = 1e-6  # Convergence tolerance threshold\n",
    "\n",
    "############################ ODE Training Loop ################################\n",
    "model_ode_list = []\n",
    "# Iterate through training batches\n",
    "for index, (t_train, x_train, y_train) in enumerate(train_loader):\n",
    "    for i in range(100):  # If training results are unstable, repeat training up to 100 times per batch\n",
    "\n",
    "        # Initialize PINN model\n",
    "        model_ode = PINN_ODE(input_num=1, output_num=num_ants * 2, bias=True).to(dtype).to(device)\n",
    "\n",
    "        # Prepare input data for ODE model\n",
    "        input_ode = (t_train.reshape(-1, 1) - t_train[0])  # Normalize time values\n",
    "        input_ode = input_ode.to(device).requires_grad_(True)\n",
    "\n",
    "        XY_test = torch.hstack((x_train, y_train))  # Stack x and y coordinates\n",
    "        XY_test = XY_test.to(device)\n",
    "\n",
    "        # Set learning rate and Adam optimizer\n",
    "        learning_rate = 0.001\n",
    "        optimizer_adam = torch.optim.Adam(model_ode.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Initialize loss tracking lists\n",
    "        loss_value_adam = []\n",
    "        loss_value_lbfgs = []\n",
    "\n",
    "        # Adam optimizer training loop\n",
    "        for i in range(epoch_adam):\n",
    "            pred_ode = model_ode(input_ode)  # Model prediction\n",
    "\n",
    "            # Set model to training mode\n",
    "            model_ode.train()\n",
    "            optimizer_adam.zero_grad()\n",
    "\n",
    "            # Compute loss\n",
    "            loss_ode = model_ode.loss(input_ode, XY_test)\n",
    "\n",
    "            # If loss is NaN or infinite, stop training\n",
    "            if not torch.isfinite(loss_ode):\n",
    "                break\n",
    "\n",
    "            # Backpropagation and optimization step\n",
    "            loss_ode.backward()\n",
    "            optimizer_adam.step()\n",
    "\n",
    "            # Store loss values\n",
    "            loss_value_adam.append(loss_ode.item())\n",
    "\n",
    "            # Early stopping condition based on loss stability\n",
    "            if i > abs(patience):\n",
    "                if (loss_value_adam[-1] <= loss_value_adam[-2] and\n",
    "                    abs(loss_value_adam[-1] - np.mean(loss_value_adam[patience:-1])) < tolerance):\n",
    "                    break\n",
    "\n",
    "        # Set up L-BFGS optimizer\n",
    "        optimizer_LBFGS = torch.optim.LBFGS(model_ode.parameters(), lr=1, max_iter=20, line_search_fn='strong_wolfe')\n",
    "\n",
    "        # L-BFGS optimization loop\n",
    "        for i in range(epoch_LBFGS):\n",
    "            loss_prev = optimizer_LBFGS.step(closure_ode)\n",
    "\n",
    "            # If loss is NaN or infinite, stop training\n",
    "            if not torch.isfinite(loss_prev):\n",
    "                break\n",
    "\n",
    "            # Store loss values\n",
    "            loss_value_lbfgs.append(loss_prev.item())\n",
    "\n",
    "            # Early stopping condition for L-BFGS\n",
    "            if i > abs(patience):\n",
    "                if (loss_value_lbfgs[-1] <= loss_value_lbfgs[-2] and\n",
    "                    abs(loss_value_lbfgs[-1] - np.mean(loss_value_lbfgs[patience:-1])) < tolerance):\n",
    "                    break\n",
    "\n",
    "        # Evaluate the trained model\n",
    "        pred = model_ode(input_ode)\n",
    "\n",
    "        # Compute the maximum radial distance of predicted positions\n",
    "        r_pred = torch.sqrt(pred[:, 0:16]**2 + pred[:, 16:]**2)\n",
    "\n",
    "        # Save the model if conditions are met\n",
    "        if model_ode.loss_data.item() < 7e-5 and torch.all(r_pred < 0.3):\n",
    "            model_ode_list.append(model_ode)\n",
    "            print(model_ode.loss_data.item())\n",
    "\n",
    "            # Save model to file\n",
    "            # Modify the path if you want to save the model in a different folder.\n",
    "            torch.save(model_ode, f'../Model/ODE_new/{num_colony}{size_ant}_step-100s_model_ode_{index}')\n",
    "\n",
    "            print(index, \"saved\")\n",
    "\n",
    "            break  # Stop further iterations if model meets criteria\n",
    "\n",
    "        # If any predicted positions exceed the radius threshold, stop training\n",
    "        elif torch.any(r_pred > 0.3):\n",
    "            break\n",
    "\n",
    "# Print total execution time\n",
    "print('Time elapsed: {:.4f}s'.format(time.time() - tik))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0bb866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rc('font', family='Arial', size=20)  # Set font to Arial\n",
    "\n",
    "# Let the user specify which model index to use\n",
    "selected_index = 0  # Change this index to select a different trained model\n",
    "\n",
    "# Ensure the selected index is within range\n",
    "if selected_index < 0 or selected_index >= len(model_ode_list):\n",
    "    raise ValueError(f\"Invalid index! Choose a number between 0 and {len(model_ode_list) - 1}.\")\n",
    "\n",
    "# Select the model based on the specified index\n",
    "model_ode = model_ode_list[selected_index]\n",
    "model_ode.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Reload corresponding training data from train_loader\n",
    "train_iter = iter(train_loader)\n",
    "\n",
    "# Iterate through train_loader until reaching the selected index\n",
    "for i in range(selected_index + 1):\n",
    "    t_train, x_train, y_train = next(train_iter)  # Load corresponding batch\n",
    "\n",
    "# Define input_ode using the selected batch\n",
    "input_ode = (t_train.reshape(-1, 1) - t_train[0]).to(device).requires_grad_(True)\n",
    "XY_test = torch.hstack((x_train, y_train)).to(device)  # Stack x, y coordinates\n",
    "\n",
    "# Generate predictions using the selected model\n",
    "pred_ode = model_ode(input_ode).detach().cpu().numpy()\n",
    "\n",
    "# Extract X, Y coordinates\n",
    "X_coords = pred_ode[:, :16]  # shape (time_steps, 16)\n",
    "Y_coords = pred_ode[:, 16:]  # shape (time_steps, 16)\n",
    "\n",
    "# Define parameters for density visualization\n",
    "radius = 0.3  # Circular area radius (meters)\n",
    "grid_spacing = 0.01  # Grid spacing (meters)\n",
    "density_grain = 0.03  # Density calculation radius\n",
    "\n",
    "# Create meshgrid within the circular area\n",
    "x = np.arange(-radius, radius + grid_spacing, grid_spacing)\n",
    "y = np.arange(-radius, radius + grid_spacing, grid_spacing)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "# Mask to consider only points inside the circular region\n",
    "mask = xx**2 + yy**2 <= radius**2\n",
    "\n",
    "# Animation setup\n",
    "fig = plt.figure(figsize=(9, 8))\n",
    "ax = plt.axes()\n",
    "\n",
    "# Colormap and colorbar settings\n",
    "cmap = plt.cm.get_cmap('BuGn')\n",
    "vmax = 8\n",
    "vmin = 0\n",
    "norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "cbar = plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), ax=ax, pad=0.02, fraction=0.046, shrink=1.0)\n",
    "\n",
    "# Adjust subplot margins to align colorbar\n",
    "plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n",
    "\n",
    "# Define animation function\n",
    "def animate(i):\n",
    "    \"\"\"\n",
    "    Update function for animation.\n",
    "    \n",
    "    Args:\n",
    "        i (int): Current frame index.\n",
    "\n",
    "    Returns:\n",
    "        ax (matplotlib.axes): Updated plot.\n",
    "    \"\"\"\n",
    "    ax.clear()\n",
    "\n",
    "    if i >= X_coords.shape[0]:  # If out of frame, keep the last frame\n",
    "        i = X_coords.shape[0] - 1\n",
    "\n",
    "    # Extract X, Y coordinates at time step i\n",
    "    x_t = X_coords[i]  # shape (16,)\n",
    "    y_t = Y_coords[i]  # shape (16,)\n",
    "\n",
    "    # Compute density at each grid point\n",
    "    density = np.zeros_like(xx, dtype=float)\n",
    "    for j, (x_grid, y_grid) in enumerate(zip(xx.ravel(), yy.ravel())):\n",
    "        distances = np.sqrt((x_t - x_grid)**2 + (y_t - y_grid)**2)\n",
    "        density.ravel()[j] = np.sum(distances <= density_grain)\n",
    "\n",
    "    # Apply mask to visualize only within the circular area\n",
    "    Z = np.zeros_like(xx, dtype=float)\n",
    "    Z[mask] = density[mask]\n",
    "\n",
    "    # Plot density map\n",
    "    ax.contourf(xx, yy, Z, levels=100, cmap=cmap, norm=norm)\n",
    "\n",
    "    # Scatter plot of agent positions\n",
    "    ax.scatter(x_t, y_t, color='black', s=200, alpha=0.2, edgecolors='none')\n",
    "\n",
    "    # Titles and labels\n",
    "    ax.set_title('Time: {:.2f}'.format(input_ode[i].item()))\n",
    "    ax.set_xlabel('$x$ (m)')\n",
    "    ax.set_ylabel('$y$ (m)')\n",
    "    ax.set_xlim(-radius, radius)\n",
    "    ax.set_ylim(-radius, radius)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Draw circular boundary\n",
    "    circle = plt.Circle((0, 0), radius=radius, color='black', linestyle='--', fill=False)\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "    return ax,\n",
    "\n",
    "# Create animation\n",
    "ani = animation.FuncAnimation(fig, animate, frames=X_coords.shape[0]+3)\n",
    "\n",
    "# To save the animation as a video file, uncomment the following line:\n",
    "# FFwriter = animation.FFMpegWriter()\n",
    "# ani.save('D:/8. 연구/240129 Collective motions for ants/Final results/movie/241128_'+str(num_colony)+size_ant+'density_rc_0.03.mp4', writer='ffmpeg', fps=10, dpi=300)\n",
    "\n",
    "\n",
    "# Display animation\n",
    "HTML(ani.to_html5_video())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2fd8fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Model prediction using selected input_ode (already defined)\n",
    "t = input_ode.reshape(len(input_ode), 1).to(device)\n",
    "pred = model_ode(t)\n",
    "\n",
    "# Compute loss and perform backward pass\n",
    "loss_ode = model_ode.loss(t, XY_test.to(device))\n",
    "loss_ode.backward()\n",
    "\n",
    "# Define animation parameters\n",
    "play_speed = 1  # Playback speed (frame interval)\n",
    "t_plot = t[::play_speed]  # Subsample time steps for animation\n",
    "\n",
    "# Extract agent positions and velocities\n",
    "half = pred.size(1) // 2  # Number of agents\n",
    "h = pred.to('cpu').detach().numpy()  # Convert to NumPy array for plotting\n",
    "velocity = model_ode.u.to('cpu').detach().numpy()  # Extract velocity field\n",
    "\n",
    "# Define colormap for agents\n",
    "color = range(half)\n",
    "cmap1 = plt.cm.get_cmap('tab20', 16)\n",
    "\n",
    "# Define animation function\n",
    "def animate(i):\n",
    "    \"\"\"\n",
    "    Update function for animation.\n",
    "    \n",
    "    Args:\n",
    "        i (int): Current frame index.\n",
    "\n",
    "    Returns:\n",
    "        ax (matplotlib.axes): Updated plot.\n",
    "    \"\"\"\n",
    "    if i >= len(t_plot):  # Keep last frame after animation ends\n",
    "        i = len(t_plot) - 1\n",
    "\n",
    "    window = 0.3  # Define plotting window size\n",
    "    f = i * play_speed  # Adjust frame index based on play speed\n",
    "    ax.clear()  # Clear previous frame\n",
    "    \n",
    "    # Define tail length for trajectory visualization\n",
    "    tail_length = int(5 / play_speed)  # Frames corresponding to 5 seconds\n",
    "    start_idx = max(f - tail_length, 0)  # Ensure index does not go below 0\n",
    "    \n",
    "    # Plot agent trajectories with dashed lines\n",
    "    for j in range(half):\n",
    "        ax.plot(h[start_idx:f+1, j], h[start_idx:f+1, half+j], linestyle='--', lw=2, alpha=0.5, color=cmap1(color[j]))\n",
    "    \n",
    "    # Scatter plot of current agent positions\n",
    "    ax.scatter(h[f, 0:half], h[f, half:], c=cmap1(color), s=200)\n",
    "\n",
    "    # Draw velocity vectors using quiver\n",
    "    origin = np.array([h[f, 0:half], h[f, half:]])  # Agent positions\n",
    "    ax.quiver(*origin, velocity[f, 0:half], velocity[f, half:], \n",
    "              scale_units='xy', angles='xy', scale=1, width=0.003, headwidth=5)\n",
    "\n",
    "    # Draw circular boundary of the arena\n",
    "    circle_arena = plt.Circle((0, 0), radius=0.285, fill=False, ls='--')\n",
    "    ax.add_artist(circle_arena)\n",
    "\n",
    "    # Set axis labels and limits\n",
    "    ax.set_title('Time: {:.2f}'.format(t_train[f].item()))\n",
    "    ax.set_xlabel('$x$ (m)')\n",
    "    ax.set_ylabel('$y$ (m)')\n",
    "    ax.set_xlim(-window, window)\n",
    "    ax.set_ylim(-window, window)\n",
    "    ax.set_aspect('equal')  # Maintain square aspect ratio\n",
    "\n",
    "# Create figure and axes for animation\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes()\n",
    "plt.subplots_adjust(left=0.15, right=0.95, top=0.9, bottom=0.1)\n",
    "\n",
    "# Generate animation\n",
    "anim = animation.FuncAnimation(fig, animate, frames=len(t_plot)+5)\n",
    "\n",
    "# Uncomment the following line to save animation as a video file\n",
    "# FFwriter = animation.FFMpegWriter()\n",
    "# anim.save('250317_Inverse_Ants_ver3.1_'+str(num_colony)+size_ant+'_0-100s.mp4', fps=10, dpi=240)\n",
    "\n",
    "# Display animation in notebook\n",
    "HTML(anim.to_html5_video())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee873715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rc('font', size=20)\n",
    "\n",
    "# 시간과 예측 값 가져오기\n",
    "t = input_ode\n",
    "t = t.reshape(len(t), 1).to(device)\n",
    "pred = model_ode(t)\n",
    "\n",
    "# 예측 결과 및 속도를 추출\n",
    "half = pred.size(1) // 2\n",
    "h = pred.to('cpu').detach().numpy()\n",
    "velocity = model_ode.u.to('cpu').detach().numpy()\n",
    "\n",
    "# 궤적을 플롯\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# 모든 에이전트의 궤적 그리기\n",
    "cmap1 = plt.cm.get_cmap('tab20', 16)\n",
    "color = range(half)\n",
    "\n",
    "for j in range(half):\n",
    "    ax.plot(h[:, j], h[:, half + j], linestyle='-', lw=2, label=f'Agent {j+1}', color=cmap1(color[j]))\n",
    "\n",
    "# 그래프 설정\n",
    "# ax.set_title('Agent Trajectories Over Time')\n",
    "ax.set_xlabel('$x$ (m)')\n",
    "ax.set_ylabel('$y$ (m)')\n",
    "ax.set_xlim(-0.3, 0.3)\n",
    "ax.set_ylim(-0.3, 0.3)\n",
    "ax.set_aspect('equal')  # x와 y 축 비율 동일하게 설정\n",
    "\n",
    "# Legend 설정: 2행으로 만들기\n",
    "# ax.legend(loc='upper right', fontsize=12, ncol=4)\n",
    "\n",
    "# 그래프 표시\n",
    "plt.tight_layout()\n",
    "# plt.savefig('D:/8. 연구/240129 Collective motions for ants/Final results/graph/'+str(num_colony)+size_ant+'_traj_pred_t=3400-3500.jpg', \n",
    "#             bbox_inches='tight', dpi=300)\n",
    "# plt.savefig('D:/8. 연구/240129 Collective motions for ants/Final results/graph/'+str(num_colony)+size_ant+'_traj_pred_t=3400-3500.eps', \n",
    "#             bbox_inches='tight', format='eps')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83941cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
