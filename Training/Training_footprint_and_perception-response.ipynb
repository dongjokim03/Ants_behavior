{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c1ee2b0",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cbf2477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib as mpl\n",
    "from IPython.display import HTML\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print('Device name:',device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cef15df",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24415a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         AntID     xcor_mm     ycor_mm  Time_frame  Colony SizeClass\n",
      "40706715   V12 -266.888916   41.477314      106082     704         S\n",
      "40706716   V13 -204.648226  147.555599      106082     704         S\n",
      "40706717   V14 -143.306903 -195.905235      106082     704         S\n",
      "40706718   V15 -260.857649  -76.024630      106082     704         S\n",
      "40706719   V16  -14.788834 -215.886498      106082     704         S\n"
     ]
    }
   ],
   "source": [
    "# Define default data type for tensors\n",
    "dtype = torch.float32  # Change to torch.double if float64 precision is preferred\n",
    "\n",
    "# Load experimental data from a CSV file\n",
    "# Specify the full file path where 'All_Data_frames.csv' is located\n",
    "data = pd.read_csv('../All_Data_frames.csv')\n",
    "print(data.tail())  # Display the last few rows of the dataset\n",
    "\n",
    "\n",
    "##### Filter data for a specific colony and ant size ####\n",
    "num_colony = 620  # Colony ID\n",
    "size_ant = 'L'  # Ant size category\n",
    "temp = data.loc[(data.Colony == num_colony) & (data.SizeClass == size_ant)][['xcor_mm', 'ycor_mm']]\n",
    "\n",
    "\n",
    "# Define time step and subsampling factor\n",
    "num_mul = 30  # Time sampling factor\n",
    "dt = 1 / 29.97 * num_mul  # Time step (seconds)\n",
    "\n",
    "# Convert position data to tensor format (meters) and downsample\n",
    "data_x = torch.tensor(temp.to_numpy()[:, 0] / 1000, dtype=dtype).reshape(-1, 16)  # X-coordinates (m)\n",
    "data_x = data_x[::num_mul, :]  # Apply sampling\n",
    "data_y = torch.tensor(temp.to_numpy()[:, 1] / 1000, dtype=dtype).reshape(-1, 16)  # Y-coordinates (m)\n",
    "data_y = data_y[::num_mul, :]  # Apply sampling\n",
    "\n",
    "# Generate time sequence tensor\n",
    "data_t = torch.linspace(0, dt * (data_x.shape[0] - 1), data_x.shape[0], dtype=dtype)\n",
    "\n",
    "# Delete original data to free memory\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c9d475",
   "metadata": {},
   "source": [
    "# Define the CustomDataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de8a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class for handling time-sequenced position data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_x, data_y, data_t):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with time (data_t), x-coordinates (data_x), and y-coordinates (data_y).\n",
    "\n",
    "        Args:\n",
    "            data_x (Tensor): X-coordinates of the ant positions.\n",
    "            data_y (Tensor): Y-coordinates of the ant positions.\n",
    "            data_t (Tensor): Time steps corresponding to position data.\n",
    "        \"\"\"\n",
    "        self.data_t = data_t\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of data points in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data_t)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a single data interval (time, x-position, y-position).\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the data point.\n",
    "\n",
    "        Returns:\n",
    "            t_train, x_train, y_train corresponding to time, x-coordinate, and y-coordinate.\n",
    "        \"\"\"\n",
    "        t_train = self.data_t[idx]\n",
    "        x_train = self.data_x[idx]\n",
    "        y_train = self.data_y[idx]\n",
    "        \n",
    "        return t_train, x_train, y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1807a2",
   "metadata": {},
   "source": [
    "# Trajectory, footprint concentration, Perception-response strategy networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de69fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trajectory networks\n",
    "\"\"\"\n",
    "\n",
    "# Define a small positive constant to prevent division by zero\n",
    "# Change to a different value if needed for numerical stability\n",
    "eps = 1e-9  \n",
    "\n",
    "class PINN_ODE(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network for training Ordinary Differential Equations (ODEs).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_num, output_num, bias=True):\n",
    "        \"\"\"\n",
    "        Initializes the neural network model.\n",
    "\n",
    "        Args:\n",
    "            input_num (int): Number of input features.\n",
    "            output_num (int): Number of output features (2 * number of ants).\n",
    "            bias (bool): Whether to use bias in linear layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_ants = output_num // 2  # Number of ants (each ant has x and y coordinates)\n",
    "        self.bias = bias\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(input_num, 32, bias=bias)\n",
    "        self.fc2 = nn.Linear(32, 32, bias=bias)\n",
    "        self.fc3 = nn.Linear(32, 32, bias=bias)\n",
    "        self.fc4 = nn.Linear(32, output_num, bias=bias)\n",
    "\n",
    "        self.reset_parameters()  # Initialize weights and biases\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Predicted output.\n",
    "        \"\"\"\n",
    "        self.input = x  # Store input values\n",
    "\n",
    "        # Normalize input data (-1 to 1)\n",
    "        x = (x - 50) / 50\n",
    "\n",
    "        # Pass through fully connected layers with activation functions\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        x = self.fc4(x) * (1e-1)  # Scale output\n",
    "\n",
    "        return x\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes network parameters using Xavier uniform initialization.\n",
    "        \"\"\"\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc2.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc3.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc4.weight, gain=1)\n",
    "\n",
    "        if self.bias:\n",
    "            nn.init.constant_(self.fc1.bias, 0.0)\n",
    "            nn.init.constant_(self.fc2.bias, 0.0)\n",
    "            nn.init.constant_(self.fc3.bias, 0.0)\n",
    "            nn.init.constant_(self.fc4.bias, 0.0)\n",
    "\n",
    "    def loss(self, x_ode, data_exp):\n",
    "        \"\"\"\n",
    "        Computes the loss function.\n",
    "\n",
    "        Args:\n",
    "            x_ode (Tensor): Input tensor representing time.\n",
    "            data_exp (Tensor): Experimental data for comparison.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Computed loss value.\n",
    "        \"\"\"\n",
    "        pred1 = self.forward(x_ode)  # Model predictions\n",
    "        num_ant = pred1.shape[1] // 2  # Number of ants\n",
    "\n",
    "        loss_func = nn.MSELoss().to(device)  # Mean Squared Error loss function\n",
    "\n",
    "        # Extract x and y positions from predicted output\n",
    "        pos_x = pred1[:, 0:num_ant]\n",
    "        pos_y = pred1[:, num_ant:]\n",
    "\n",
    "        # Compute the magnitude of position vectors\n",
    "        self.r_mag = torch.sqrt(torch.square(pos_x) + torch.square(pos_y))\n",
    "\n",
    "        ####### Compute velocity of ants #########\n",
    "        for i in range(pred1.size(1)):\n",
    "            temp = torch.zeros_like(pred1)\n",
    "            temp[:, i] = 1\n",
    "            grads, = autograd.grad(pred1, self.input, grad_outputs=temp, create_graph=True)\n",
    "            if i == 0:\n",
    "                self.u = grads  # Initialize velocity tensor\n",
    "            else:\n",
    "                self.u = torch.hstack((self.u, grads))  # Stack velocity components\n",
    "\n",
    "        # Extract velocity components\n",
    "        self.vel_x = self.u[:, 0:num_ant]\n",
    "        self.vel_y = self.u[:, num_ant:]\n",
    "\n",
    "        # Compute velocity magnitude\n",
    "        self.u_mag = torch.sqrt(torch.square(self.vel_x) + torch.square(self.vel_y))\n",
    "\n",
    "        # Normalize velocity components to obtain unit vectors\n",
    "        self.vel_x_unit = self.vel_x / self.u_mag\n",
    "        self.vel_y_unit = self.vel_y / self.u_mag\n",
    "\n",
    "        ####### Compute acceleration of ants #########\n",
    "        for i in range(pred1.size(1)):\n",
    "            temp = torch.zeros_like(pred1)\n",
    "            temp[:, i] = 1\n",
    "            grads, = autograd.grad(self.u, self.input, grad_outputs=temp, create_graph=True)\n",
    "            if i == 0:\n",
    "                self.accel = grads  # Initialize acceleration tensor\n",
    "            else:\n",
    "                self.accel = torch.hstack((self.accel, grads))  # Stack acceleration components\n",
    "\n",
    "        # Compute loss between predictions and experimental data\n",
    "        self.loss_data = loss_func(pred1, data_exp)\n",
    "\n",
    "        # Total loss (currently only data loss is considered)\n",
    "        loss_ode = self.loss_data\n",
    "\n",
    "        return loss_ode\n",
    "\n",
    "\n",
    "def closure_ode():\n",
    "    \"\"\"\n",
    "    Closure function for the L-BFGS optimizer.\n",
    "\n",
    "    This function evaluates the loss function and performs backpropagation\n",
    "    for updating the neural network parameters.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Computed loss value.\n",
    "    \"\"\"\n",
    "    global loss_value_ode_LBFGS, iter_num\n",
    "\n",
    "    model_ode.train()\n",
    "    optimizer_LBFGS.zero_grad()\n",
    "\n",
    "    # Compute ODE loss\n",
    "    loss_ode = model_ode.loss(input_ode, XY_test.to(device))\n",
    "\n",
    "    # Perform backpropagation only if loss is finite\n",
    "    if torch.isfinite(loss_ode).item():\n",
    "        loss_ode.backward() \n",
    "\n",
    "    return loss_ode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f35bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Footprint concentration networks\n",
    "\"\"\"\n",
    "eps = 1e-9\n",
    "class PINN_PDE(nn.Module):\n",
    "    \"\"\"\n",
    "    Physics-Informed Neural Network (PINN) for solving the PDE governing\n",
    "    footprint concentration dynamics.\n",
    "\n",
    "    This network models the spatiotemporal evolution of ant footprints by learning\n",
    "    from the PDE:\n",
    "        ∂c/∂t = D ∇^2 c + k_p H(r; a) - k_m c\n",
    "    where H is the heaviside step function representing footprint deposition at positions r, and c is the concentration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_num, output_num, bias=True):\n",
    "        \"\"\"\n",
    "        Initializes the PINN model.\n",
    "\n",
    "        Args:\n",
    "            input_num (int): Number of input features (typically t, x, y → 3).\n",
    "            output_num (int): Number of output features (typically 1, for scalar field c).\n",
    "            bias (bool): Whether to include bias in linear layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.bias = bias\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(input_num, 32, bias=bias)\n",
    "        self.fc2 = nn.Linear(32, 32, bias=bias)\n",
    "        self.fc3 = nn.Linear(32, 32, bias=bias)\n",
    "        self.fc4 = nn.Linear(32, output_num, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "        # PDE parameters\n",
    "        self.kp = 0.01            # Footprint production rate\n",
    "        self.km = 0.2             # Footprint decay rate\n",
    "        self.ph_r = 0.03          # Production radius (approx. ant body size)\n",
    "        self.boundary = 0.0       # Decision boundary for classification of active ants\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the PINN.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (N, 3) with [t, x, y].\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Predicted footprint concentration c(t, x, y).\n",
    "        \"\"\"\n",
    "        self.input = x\n",
    "\n",
    "        # Normalize input:\n",
    "        #   - Time t normalized (-1 to 1)\n",
    "        #   - Space x, y normalized by arena radius (0.28 m)\n",
    "        x_t = (x[:, 0:1] - 50) / 50\n",
    "        x_xy = x[:, 1:] / 0.28\n",
    "        x = torch.cat((x_t, x_xy), dim=1)\n",
    "\n",
    "        # Pass through the network with tanh activations\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "\n",
    "        # Final layer uses softplus to ensure positivity of output (concentration ≥ 0)\n",
    "        x = F.softplus(self.fc4(x)) * 0.1  # Output scaled for stability\n",
    "\n",
    "        return x\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the network parameters using Xavier uniform initialization.\n",
    "        \"\"\"\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc2.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc3.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc4.weight, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "        if self.bias:\n",
    "            nn.init.constant_(self.fc1.bias, 0.0)\n",
    "            nn.init.constant_(self.fc2.bias, 0.0)\n",
    "            nn.init.constant_(self.fc3.bias, 0.0)\n",
    "            nn.init.constant_(self.fc4.bias, 0.0)\n",
    "\n",
    "            \n",
    "def loss(model_ode, model_pde, model_anten, x_ode, x_pde, mask):\n",
    "    \"\"\"\n",
    "    Computes the total loss for the footprint concentration and response strategy coupled system:\n",
    "    - Just recall the trajectory loss\n",
    "    - PDE loss from footprint concentration\n",
    "    - Normal acceleration loss from perception-response based on gradient sensing\n",
    "\n",
    "    Args:\n",
    "        model_ode (nn.Module): Trained trajectory model (PINN_ODE).\n",
    "        model_pde (nn.Module): Concentration field model solving PDE for footprint concentration field (PINN_PDE).\n",
    "        model_anten (nn.Module): Perception-response model (e.g., Mechanism_NN).\n",
    "        x_ode (Tensor): Temporal input for trajectory model, shape (N, 1).\n",
    "        x_pde (Tensor): Spatiotemporal input for concentration field model, shape (M, 3).\n",
    "        mask (Tensor): Boolean mask to select agent positions from the full PDE input.\n",
    "\n",
    "    Returns:\n",
    "        loss_data (Tensor): trajectory position loss from model_ode\n",
    "        loss_theta (Tensor): perception-response loss\n",
    "        loss_concent (Tensor): concentration PDE residual loss\n",
    "        loss_total (Tensor): total weighted loss\n",
    "    \"\"\"\n",
    "\n",
    "    loss_func = nn.MSELoss().to(device)\n",
    "\n",
    "    # Forward prediction from PDE model\n",
    "    pred_pde = model_pde(x_pde)  # c(t, x, y)\n",
    "\n",
    "    # Retrieve trajectory-related losses from the ODE model\n",
    "    loss_data = model_ode.loss_data\n",
    "\n",
    "    u_mag = model_ode.u_mag                        # Agent speed magnitude\n",
    "    vel_x_unit = model_ode.vel_x_unit              # x-direction unit velocity\n",
    "    vel_y_unit = model_ode.vel_y_unit              # y-direction unit velocity\n",
    "\n",
    "    # Compute gradients of c(t, x, y)\n",
    "    dc_dt_dx_dy = autograd.grad(pred_pde, x_pde, torch.ones([x_pde.shape[0], 1]).to(device), create_graph=True)[0]\n",
    "    dc_dt = dc_dt_dx_dy[:, [0]]                    # ∂c/∂t\n",
    "    dc_dx = dc_dt_dx_dy[:, [1]]                    # ∂c/∂x\n",
    "    dc_dy = dc_dt_dx_dy[:, [2]]                    # ∂c/∂y\n",
    "\n",
    "    # Decompose gradients in velocity-aligned directions\n",
    "    dc_normal = (-vel_y_unit.reshape(-1, 1) * dc_dx[mask]) + (vel_x_unit.reshape(-1, 1) * dc_dy[mask])     # Concentration gradeint normal to velocity\n",
    "    dc_parallel = (vel_x_unit.reshape(-1, 1) * dc_dx[mask]) + (vel_y_unit.reshape(-1, 1) * dc_dy[mask])    # Concentration gradeint parallel to velocity\n",
    "\n",
    "    # Select dc_normal entries for active ants\n",
    "    dc_normal_sel = (dc_normal.reshape(-1, 16)[1:-1][mask_u_mag_tensor[1:-1]]).reshape(-1, 1)\n",
    "\n",
    "    # Decompose acceleration\n",
    "    accel_tan = (model_ode.accel[:, 0:num_ants] * (-vel_y_unit)) + (model_ode.accel[:, num_ants:] * vel_x_unit)   # acceleration normal to velocity\n",
    "    accel_parallel = (model_ode.accel[:, 0:num_ants] * vel_x_unit) + (model_ode.accel[:, num_ants:] * vel_y_unit)   # acceleration parallel to velocity\n",
    "\n",
    "    # Select acceleration and velocity magnitudes for active ants\n",
    "    accel_tan_sel = accel_tan[1:-1][mask_u_mag_tensor[1:-1]]\n",
    "    u_mag_sel = u_mag[1:-1][mask_u_mag_tensor[1:-1]]\n",
    "\n",
    "    # Compute local footprint deposition strength based on distance from agents\n",
    "    dist_value = torch.sqrt(torch.square(x_pde[:,1].unsqueeze(1) - \n",
    "                                         (x_pde[:,1:2][mask]).reshape(-1,num_ants).repeat_interleave(x_pde.shape[0]//x_ode.shape[0],dim=0)) +\\\n",
    "                            torch.square(x_pde[:,2].unsqueeze(1) - \n",
    "                                         (x_pde[:,2:3][mask]).reshape(-1,num_ants).repeat_interleave(x_pde.shape[0]//x_ode.shape[0],dim=0)))\n",
    "\n",
    "    dist_mask = dist_value - model_pde.ph_r\n",
    "\n",
    "    local_dist_func = torch.sum(\n",
    "        torch.where(dist_mask <= 0, dist_mask, torch.zeros_like(dist_mask)) / (dist_mask+eps),\n",
    "        dim=1,\n",
    "        keepdim=True\n",
    "    )\n",
    "\n",
    "    # Compute production and decay terms for PDE\n",
    "    f = model_pde.kp * local_dist_func - model_pde.km * pred_pde\n",
    "\n",
    "    # Compute perception-response using local gradient sensing\n",
    "    g = model_anten(dc_normal_sel)\n",
    "\n",
    "    # Loss: rate of angle change driven by perception-response vs actual normal acceleration\n",
    "    loss_theta = loss_func(accel_tan_sel.flatten(), g.flatten() * u_mag_sel.flatten())\n",
    "\n",
    "    # PDE residual loss: ∂c/∂t ≈ f\n",
    "    loss_concent = loss_func(dc_dt, f)\n",
    "\n",
    "    # Total loss (weighted sum)\n",
    "    loss_total = 1 * loss_theta + 20 * loss_concent\n",
    "\n",
    "    return loss_data, loss_theta, loss_concent, loss_total\n",
    "\n",
    "\n",
    "def closure_pde():\n",
    "    \"\"\"\n",
    "    Closure function for L-BFGS optimization during PINN training.\n",
    "\n",
    "    It is used by the L-BFGS optimizer to evaluate the loss and gradients \n",
    "    at each iteration.\n",
    "\n",
    "    Returns:\n",
    "        loss_total (Tensor)\n",
    "    \"\"\"\n",
    "    global loss_value_LBFGS, iter_num, XY_test\n",
    "\n",
    "    # Evaluate the ODE model's internal loss\n",
    "    loss_ode = model_ode.loss(input_ode, data_exp=XY_test)\n",
    "\n",
    "    # Set PDE model to training mode and clear previous gradients\n",
    "    model_pde.train()\n",
    "    optimizer_LBFGS.zero_grad()\n",
    "\n",
    "    # Compute total loss and its components\n",
    "    loss_data, loss_theta, loss_concent, loss_total = \\\n",
    "        loss(model_ode, model_pde, model_anten, input_ode, input_pde, mask)\n",
    "\n",
    "    # Backpropagate only if the loss is finite\n",
    "    if torch.isfinite(loss_total).item():\n",
    "        loss_total.backward()\n",
    "    else:\n",
    "        pass  # Skip backward pass if loss is NaN or Inf\n",
    "\n",
    "    return loss_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ecd3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perception-response networks\n",
    "\"\"\"\n",
    "\n",
    "class Mechanism_NN(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network to infer response mechanisms from input data.\n",
    "\n",
    "    This architecture consists of 3 fully connected layers with sigmoid activations\n",
    "    in the hidden layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_num, output_num, bias=True):\n",
    "        \"\"\"\n",
    "        Initializes the Mechanism_NN model.\n",
    "\n",
    "        Args:\n",
    "            input_num (int): Number of input features.\n",
    "            output_num (int): Number of output features.\n",
    "            bias (bool): Whether to include bias terms in linear layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.bias = bias\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(input_num, 8, bias=bias)\n",
    "        self.fc2 = nn.Linear(8, 8, bias=bias)\n",
    "        self.fc3 = nn.Linear(8, output_num, bias=bias)\n",
    "\n",
    "        self.reset_parameters()  # Initialize weights and biases\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the network.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, input_num).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor of shape (batch_size, output_num).\n",
    "        \"\"\"\n",
    "        self.input = x  # Store input for external access if needed\n",
    "\n",
    "        # Apply scaling and pass through the network\n",
    "        x = self.fc1(x * 5)           # Scale input and apply first linear layer\n",
    "        x = torch.sigmoid(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)              # Output layer (no activation)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes weights using Xavier uniform initialization and biases to zero.\n",
    "        \"\"\"\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain=nn.init.calculate_gain('sigmoid'))\n",
    "        nn.init.xavier_uniform_(self.fc2.weight, gain=nn.init.calculate_gain('sigmoid'))\n",
    "        nn.init.xavier_uniform_(self.fc3.weight, gain=1)\n",
    "\n",
    "        if self.bias:\n",
    "            nn.init.constant_(self.fc1.bias, 0.0)\n",
    "            nn.init.constant_(self.fc2.bias, 0.0)\n",
    "            nn.init.constant_(self.fc3.bias, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18da297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define time (T), x-coordinates (X), and y-coordinates (Y) ###\n",
    "\n",
    "num_t = 100  # Number of time steps\n",
    "\n",
    "# Create dataset and data loader for training\n",
    "dataset = CustomDataset(data_x, data_y, data_t)\n",
    "train_loader = DataLoader(dataset, batch_size=num_t, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e6c497",
   "metadata": {},
   "source": [
    "# Classification of active and inactive ants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf58ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group decision boundary u_mag value: 0.0054\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define number of ants in group\n",
    "num_ants = 16\n",
    "\n",
    "# List to store velocity magnitudes from all trained ODE models\n",
    "u_mag = []\n",
    "\n",
    "# Iterate over trajectory batches and collect u_mag from each model\n",
    "for index, (t_train, x_train, y_train) in enumerate(train_loader):\n",
    "    model_ode_path = '../Model/ODE/'+str(num_colony) + str(size_ant) + '_step-100s_model_ode_' + str(index)\n",
    "\n",
    "    # Load pre-trained ODE model if it exists\n",
    "    if os.path.exists(model_ode_path):\n",
    "        model_ode = torch.load(model_ode_path)\n",
    "\n",
    "    # Move model to appropriate device and precision\n",
    "    model_ode = model_ode.to(device).to(dtype=data_t.dtype)\n",
    "\n",
    "    # Prepare input tensor\n",
    "    input_ode = (t_train.reshape(-1, 1) - t_train[0]).to(device).requires_grad_(True)\n",
    "    XY_test = torch.hstack((x_train, y_train)).to(device)\n",
    "\n",
    "    # Forward pass and compute internal dynamics (including u_mag)\n",
    "    _ = model_ode(input_ode)\n",
    "    _ = model_ode.loss(input_ode, XY_test)\n",
    "\n",
    "    # Store velocity magnitude values\n",
    "    u_mag.append(model_ode.u_mag.flatten().to('cpu').detach().numpy())\n",
    "\n",
    "# Convert collected magnitudes to 2D NumPy array for GMM\n",
    "u_mag_array = np.array(u_mag)\n",
    "u_mag_np = u_mag_array.flatten().reshape(-1, 1)\n",
    "\n",
    "# Apply Gaussian Mixture Model (GMM) with 2 components\n",
    "# This separates ants into low-speed (inactive) and high-speed (active) groups\n",
    "gmm = GaussianMixture(n_components=2, random_state=0, max_iter=100, init_params='kmeans')\n",
    "gmm.fit(u_mag_np)\n",
    "\n",
    "# Predict group labels\n",
    "labels = gmm.predict(u_mag_np)\n",
    "\n",
    "# Identify which group has higher average speed\n",
    "group_means = gmm.means_.flatten()\n",
    "larger_group_label = np.argmax(group_means)\n",
    "smaller_group_label = 1 - larger_group_label\n",
    "\n",
    "# Separate data by group label\n",
    "u_mag_larger_group = u_mag_np[labels == larger_group_label].flatten()\n",
    "u_mag_smaller_group = u_mag_np[labels == smaller_group_label].flatten()\n",
    "\n",
    "# Compute decision boundary between two groups\n",
    "# Boundary = midpoint between max(small group) and min(large group)\n",
    "decision_boundary = (np.max(u_mag_smaller_group) + np.min(u_mag_larger_group)) / 2\n",
    "\n",
    "print(f\"Group decision boundary u_mag value: {decision_boundary:.4f}\")\n",
    "\n",
    "# Plot histogram of velocity magnitudes with color-coded groups\n",
    "bins = np.arange(0, np.max(u_mag_np) + 0.001, 0.001)\n",
    "\n",
    "color_gray = np.array([150, 150, 150]) / 255\n",
    "color_blue = np.array([0, 100, 250]) / 255\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Plot smaller group (likely inactive)\n",
    "plt.hist(u_mag_smaller_group, bins=bins, color=color_gray, alpha=0.9,\n",
    "         edgecolor='black', label='Smaller Mean Group')\n",
    "\n",
    "# Plot larger group (likely active)\n",
    "plt.hist(u_mag_larger_group, bins=bins, color=color_blue, alpha=0.9,\n",
    "         edgecolor='black', label='Larger Mean Group')\n",
    "\n",
    "# Draw vertical line for decision boundary\n",
    "plt.axvline(x=decision_boundary, color='tab:orange', linestyle='--', linewidth=2,\n",
    "            label=f'Boundary: {decision_boundary:.4f}')\n",
    "\n",
    "# Set axis labels (no title for cleaner figure)\n",
    "plt.xlabel('$v$')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8247ff27",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0bb866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-25 10:53:05.502548\n",
      "STEP: 0, Iter: 464, L_data: 3.20e-05, L_ang: 9.75e-06, L_c: 1.23e-05, COR_tan: 9.47e-01\n",
      "save\n",
      "STEP: 1, Iter: 492, L_data: 2.95e-05, L_ang: 1.79e-05, L_c: 1.18e-05, COR_tan: 8.72e-01\n",
      "save\n",
      "STEP: 2, Iter: 509, L_data: 3.47e-05, L_ang: 1.55e-05, L_c: 1.36e-05, COR_tan: 9.05e-01\n",
      "save\n",
      "STEP: 3, Iter: 531, L_data: 2.55e-05, L_ang: 1.07e-05, L_c: 1.18e-05, COR_tan: 9.49e-01\n",
      "save\n",
      "STEP: 4, Iter: 429, L_data: 3.88e-05, L_ang: 1.04e-05, L_c: 1.42e-05, COR_tan: 9.38e-01\n",
      "save\n",
      "STEP: 5, Iter: 424, L_data: 2.59e-05, L_ang: 2.01e-05, L_c: 1.25e-05, COR_tan: 8.98e-01\n",
      "save\n",
      "STEP: 6, Iter: 607, L_data: 2.74e-05, L_ang: 8.27e-06, L_c: 1.10e-05, COR_tan: 9.42e-01\n",
      "save\n",
      "STEP: 7, Iter: 400, L_data: 3.34e-05, L_ang: 1.62e-05, L_c: 1.24e-05, COR_tan: 8.72e-01\n",
      "save\n",
      "STEP: 8, Iter: 316, L_data: 2.59e-05, L_ang: 1.13e-05, L_c: 1.10e-05, COR_tan: 9.03e-01\n",
      "save\n",
      "STEP: 9, Iter: 558, L_data: 2.18e-05, L_ang: 1.12e-05, L_c: 1.21e-05, COR_tan: 8.90e-01\n",
      "save\n",
      "STEP: 10, Iter: 399, L_data: 2.06e-05, L_ang: 1.21e-05, L_c: 9.56e-06, COR_tan: 8.64e-01\n",
      "save\n",
      "STEP: 11, Iter: 293, L_data: 1.95e-05, L_ang: 1.10e-05, L_c: 9.43e-06, COR_tan: 8.64e-01\n",
      "save\n",
      "STEP: 12, Iter: 414, L_data: 2.33e-05, L_ang: 9.55e-06, L_c: 1.05e-05, COR_tan: 9.38e-01\n",
      "save\n",
      "STEP: 13, Iter: 341, L_data: 3.20e-05, L_ang: 1.01e-05, L_c: 9.76e-06, COR_tan: 8.66e-01\n",
      "save\n",
      "STEP: 14, Iter: 348, L_data: 2.17e-05, L_ang: 1.39e-05, L_c: 9.96e-06, COR_tan: 9.11e-01\n",
      "save\n",
      "STEP: 15, Iter: 407, L_data: 2.58e-05, L_ang: 1.98e-05, L_c: 1.10e-05, COR_tan: 8.79e-01\n",
      "save\n",
      "STEP: 16, Iter: 435, L_data: 2.26e-05, L_ang: 9.81e-06, L_c: 9.03e-06, COR_tan: 8.75e-01\n",
      "save\n",
      "STEP: 17, Iter: 395, L_data: 2.43e-05, L_ang: 9.47e-06, L_c: 8.97e-06, COR_tan: 9.51e-01\n",
      "save\n",
      "STEP: 18, Iter: 488, L_data: 2.25e-05, L_ang: 9.38e-06, L_c: 9.01e-06, COR_tan: 9.41e-01\n",
      "save\n",
      "STEP: 19, Iter: 406, L_data: 2.76e-05, L_ang: 1.37e-05, L_c: 1.04e-05, COR_tan: 9.03e-01\n",
      "save\n",
      "STEP: 20, Iter: 360, L_data: 2.72e-05, L_ang: 1.17e-05, L_c: 1.00e-05, COR_tan: 8.66e-01\n",
      "save\n",
      "STEP: 21, Iter: 429, L_data: 2.65e-05, L_ang: 2.54e-05, L_c: 1.15e-05, COR_tan: 8.28e-01\n",
      "save\n",
      "STEP: 22, Iter: 638, L_data: 2.18e-05, L_ang: 9.31e-06, L_c: 9.46e-06, COR_tan: 8.81e-01\n",
      "save\n",
      "STEP: 23, Iter: 374, L_data: 2.28e-05, L_ang: 1.53e-05, L_c: 1.14e-05, COR_tan: 8.45e-01\n",
      "save\n",
      "STEP: 24, Iter: 336, L_data: 2.41e-05, L_ang: 1.27e-05, L_c: 9.63e-06, COR_tan: 8.69e-01\n",
      "save\n",
      "STEP: 25, Iter: 348, L_data: 2.53e-05, L_ang: 1.37e-05, L_c: 1.16e-05, COR_tan: 8.61e-01\n",
      "save\n",
      "STEP: 26, Iter: 393, L_data: 2.34e-05, L_ang: 1.40e-05, L_c: 9.33e-06, COR_tan: 8.69e-01\n",
      "save\n",
      "STEP: 27, Iter: 432, L_data: 3.61e-05, L_ang: 2.01e-05, L_c: 1.12e-05, COR_tan: 8.13e-01\n",
      "save\n",
      "STEP: 28, Iter: 335, L_data: 3.09e-05, L_ang: 1.19e-05, L_c: 8.58e-06, COR_tan: 8.83e-01\n",
      "save\n",
      "STEP: 29, Iter: 440, L_data: 2.29e-05, L_ang: 1.10e-05, L_c: 9.50e-06, COR_tan: 8.42e-01\n",
      "save\n",
      "STEP: 30, Iter: 638, L_data: 1.95e-05, L_ang: 5.81e-06, L_c: 9.35e-06, COR_tan: 9.24e-01\n",
      "save\n",
      "STEP: 31, Iter: 464, L_data: 1.22e-05, L_ang: 3.88e-06, L_c: 5.67e-06, COR_tan: 9.07e-01\n",
      "save\n",
      "STEP: 32, Iter: 375, L_data: 1.39e-05, L_ang: 6.60e-06, L_c: 6.40e-06, COR_tan: 9.44e-01\n",
      "save\n",
      "STEP: 33, Iter: 496, L_data: 1.38e-05, L_ang: 5.73e-06, L_c: 5.70e-06, COR_tan: 8.74e-01\n",
      "save\n",
      "STEP: 34, Iter: 753, L_data: 1.23e-05, L_ang: 4.50e-06, L_c: 1.09e-05, COR_tan: 9.66e-01\n",
      "save\n",
      "time: 230236.7181s\n"
     ]
    }
   ],
   "source": [
    "# Start timer and print current timestamp\n",
    "tik = time.time()\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "\n",
    "# Training hyperparameters\n",
    "num_ants = 16\n",
    "epoch_adam = 100\n",
    "epoch_LBFGS = 1500\n",
    "patience = -51\n",
    "tolerance = 5e-7\n",
    "\n",
    "loss_pde = []\n",
    "repeat_num = 5\n",
    "\n",
    "# Iterate over trajectory batches\n",
    "for index, (t_train, x_train, y_train) in enumerate(train_loader):\n",
    "\n",
    "    for kkk in range(repeat_num):  # Repeat training attempt (for retry if failed)\n",
    "\n",
    "        # Initialize models\n",
    "        model_pde = PINN_PDE(input_num=3, output_num=1, bias=True).to(device).to(dtype=data_t.dtype)\n",
    "        model_anten = Mechanism_NN(input_num=1, output_num=1, bias=True).to(device).to(dtype=data_t.dtype)\n",
    "        model_ode_path = '../Model/ODE/'+str(num_colony) + str(size_ant) + '_step-100s_model_ode_' + str(index)\n",
    "\n",
    "        # Skip if ODE model doesn't exist\n",
    "        if not os.path.exists(model_ode_path):\n",
    "            continue\n",
    "\n",
    "        model_ode = torch.load(model_ode_path).to(device).to(dtype=data_t.dtype)\n",
    "        params = list(model_pde.parameters()) + list(model_anten.parameters())\n",
    "        optimizer_adam = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "        # Prepare ODE input and reference data\n",
    "        input_ode = (t_train.reshape(-1, 1) - t_train[0]).to(device).requires_grad_(True)\n",
    "        XY_test = torch.hstack((x_train, y_train)).to(device)\n",
    "\n",
    "        pred_ode = model_ode(input_ode)\n",
    "\n",
    "        # Construct PDE input from ODE prediction\n",
    "        pde_t = input_ode\n",
    "        pos_x = pred_ode[:, :num_ants]\n",
    "        pos_y = pred_ode[:, num_ants:]\n",
    "\n",
    "        T_pde, X_pde = torch.meshgrid(pde_t.flatten(), pos_x.flatten().clone().detach(), indexing='ij')\n",
    "        _, Y_pde = torch.meshgrid(pde_t.flatten(), pos_y.flatten().clone().detach(), indexing='ij')\n",
    "        input_pde = torch.vstack((T_pde.flatten(), X_pde.flatten(), Y_pde.flatten())).transpose(1,0)            \n",
    "        input_pde = input_pde.clone().detach().to(device).requires_grad_(True)\n",
    "\n",
    "        num_t = pred_ode.shape[0]\n",
    "\n",
    "        # Create mask for active ants using u_mag and GMM decision boundary (Don't change the name 'mask_u_mag_tensor')\n",
    "        model_ode.loss(input_ode, data_exp=XY_test)\n",
    "        u_mag_np = model_ode.u_mag.flatten().cpu().detach().numpy().reshape(-1, 1)\n",
    "        mask_u_mag = u_mag_np >= decision_boundary\n",
    "        mask_u_mag_tensor = torch.tensor(mask_u_mag, dtype=torch.bool).view(model_ode.u_mag.shape).to(device)\n",
    "\n",
    "        # Match ODE time indices to PDE time-expanded grid\n",
    "        mask = torch.zeros(num_t * num_t * num_ants, 1)\n",
    "        for j in range(num_t):\n",
    "            start = j * (num_t * num_ants) + j * num_ants\n",
    "            mask[start:start + num_ants] = 1\n",
    "        mask = mask.bool().squeeze(1).to(device)\n",
    "\n",
    "        # ----------------------- ADAM Optimization -----------------------\n",
    "        loss_value_pde_adam = []\n",
    "\n",
    "        for ii in range(epoch_adam):\n",
    "            model_pde.train()\n",
    "            optimizer_adam.zero_grad()\n",
    "\n",
    "            model_ode.loss(input_ode, data_exp=XY_test)\n",
    "\n",
    "            loss_data, loss_theta, loss_concent, loss_total = loss(\n",
    "                model_ode, model_pde, model_anten, input_ode, input_pde, mask)\n",
    "\n",
    "            if not torch.isfinite(loss_total):\n",
    "                break\n",
    "\n",
    "            loss_total.backward()\n",
    "            optimizer_adam.step()\n",
    "\n",
    "            loss_value_pde_adam.append(loss_total.item())\n",
    "\n",
    "            if ii > abs(patience):\n",
    "                recent = loss_value_pde_adam[patience:-1]\n",
    "                if loss_value_pde_adam[-1] <= loss_value_pde_adam[-2] and \\\n",
    "                abs(loss_value_pde_adam[-1] - np.mean(recent)) < tolerance:\n",
    "                    break\n",
    "\n",
    "        # ----------------------- L-BFGS Optimization -----------------------\n",
    "        loss_value_pde_lbfgs = []\n",
    "\n",
    "        optimizer_LBFGS = torch.optim.LBFGS(params, lr=1, max_iter=20, line_search_fn='strong_wolfe')\n",
    "\n",
    "        for i in range(epoch_LBFGS):\n",
    "            loss_prev = optimizer_LBFGS.step(closure_pde)\n",
    "\n",
    "            if not torch.isfinite(loss_prev):\n",
    "                break\n",
    "\n",
    "            loss_value_pde_lbfgs.append(loss_prev.item())\n",
    "\n",
    "            if i > abs(patience):\n",
    "                recent = loss_value_pde_lbfgs[patience:-1]\n",
    "                if loss_value_pde_lbfgs[-1] <= loss_value_pde_lbfgs[-2] and \\\n",
    "                abs(loss_value_pde_lbfgs[-1] - np.mean(recent)) < tolerance:\n",
    "                    break\n",
    "\n",
    "        # ----------------------- Evaluation & Correlation -----------------------\n",
    "        loss_data, loss_theta, loss_concent, loss_total = \\\n",
    "        loss(model_ode, model_pde, model_anten,input_ode, input_pde, mask = mask)\n",
    "        \n",
    "        model_ode.loss(input_ode, XY_test.to(device))\n",
    "        pred_ode = model_ode(input_ode)\n",
    "        pred_pde = model_pde(input_pde)\n",
    "\n",
    "        dc_dt_dx_dy = autograd.grad(pred_pde, input_pde, torch.ones_like(pred_pde), create_graph=True)[0]\n",
    "        dc_dx, dc_dy = dc_dt_dx_dy[:, [1]], dc_dt_dx_dy[:, [2]]\n",
    "\n",
    "        vel_x_unit = model_ode.vel_x_unit\n",
    "        vel_y_unit = model_ode.vel_y_unit\n",
    "\n",
    "        dc_normal = (-vel_y_unit.reshape(-1, 1) * dc_dx[mask]) + (vel_x_unit.reshape(-1, 1) * dc_dy[mask])\n",
    "        dc_normal_sel = (dc_normal.reshape(-1, num_ants)[1:-1][mask_u_mag_tensor[1:-1]]).reshape(-1, 1)\n",
    "\n",
    "        accel_tan = (model_ode.accel[:, :num_ants] * -vel_y_unit) + (model_ode.accel[:, num_ants:] * vel_x_unit)\n",
    "        accel_tan_sel = accel_tan[1:-1][mask_u_mag_tensor[1:-1]]\n",
    "        u_mag_sel = model_ode.u_mag[1:-1][mask_u_mag_tensor[1:-1]]\n",
    "\n",
    "        c_func = model_anten(dc_normal_sel)\n",
    "\n",
    "        accel_tan_np = accel_tan_sel.flatten().to('cpu').detach().numpy()\n",
    "        c_func_np = c_func.flatten().to('cpu').detach().numpy()\n",
    "        dc_normal_np = dc_normal_sel.flatten().to('cpu').detach().numpy()\n",
    "        u_mag_np = u_mag_sel.flatten().to('cpu').detach().numpy()\n",
    "\n",
    "        # Compute correlation between predicted response and actual tangential acceleration\n",
    "        corr_tan = np.corrcoef(\n",
    "            accel_tan_sel.flatten().cpu().detach().numpy(),\n",
    "            (c_func.flatten() * u_mag_sel.flatten()).cpu().detach().numpy()\n",
    "        )[0, 1]\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        # Print training/evaluation status for the current step\n",
    "        # L_data: Trajectory fitting loss\n",
    "        # L_ang: Perception-response loss\n",
    "        # L_c: Concentration field loss\n",
    "        # COR_tan: Correlation between predicted and actual tangential acceleration\n",
    "        \"\"\"\n",
    "        \n",
    "        print('STEP: %d, Iter: %d, L_data: %.2e, L_ang: %.2e, L_c: %.2e, COR_tan: %.2e' %\n",
    "              (index, i, model_ode.loss_data.item(), loss_theta.item(), loss_concent.item(), corr_tan))\n",
    "\n",
    "        # Save models if training succeeds or after second attempt\n",
    "        if (i > 200 and loss_concent.item() < 3e-5 and corr_tan > 0.75) or kkk == repeat_num-1:\n",
    "            \"\"\"\n",
    "            # Optional: Visualize learned perception-response mechanism\n",
    "            # Activate the # lines below to enable visualization for each interval\n",
    "\n",
    "            \"\"\"\n",
    "#             fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "#             # Scatter plot: G(∇⊥c) vs aₙ\n",
    "#             axs[0].scatter(dc_normal_np, c_func_np, s=5, label=\"$G(\\\\nabla_\\\\perp c)$\")\n",
    "#             axs[0].set_xlabel('$\\\\nabla_\\\\perp c$')\n",
    "#             axs[0].set_ylabel('$a_{n}$')\n",
    "#             axs[0].set_xlim(-8, 8)\n",
    "\n",
    "#             # Scatter plot: G(∇⊥c)·|v| vs measured tangential acceleration\n",
    "#             axs[1].scatter(c_func_np * u_mag_np, accel_tan_np)\n",
    "#             axs[1].set_xlabel('NN($\\\\nabla_\\\\perp c$), NN($\\\\nabla_\\\\parallel c$)')\n",
    "#             axs[1].set_xlim(-0.05, 0.05)\n",
    "\n",
    "#             plt.show()\n",
    "\n",
    "            # Save model and log loss\n",
    "            model_pde.boundary = decision_boundary\n",
    "            loss_pde.append(loss_concent.item())\n",
    "\n",
    "            torch.save(model_pde, '../Model/PDE/'+str(num_colony) + size_ant + '_step-100s_model_pde_' + str(index))\n",
    "            torch.save(model_anten, '../Model/PDE/'+str(num_colony) + size_ant + '_step-100s_model_anten_' + str(index))\n",
    "            print('save')\n",
    "            break\n",
    "\n",
    "# Print total training time\n",
    "print('time: {:.4f}s'.format(time.time() - tik))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0a0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
